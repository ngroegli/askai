services:
  askai-api:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
    environment:
      - FLASK_ENV=development
      - FLASK_DEBUG=true
      - FLASK_HOST=0.0.0.0
      - FLASK_PORT=8080
      - ASKAI_VERSION=1.2.1
      # AskAI Configuration - Set your actual API key here
      - API_KEY=${OPENROUTER_API_KEY:-dummy-key}
      - DEFAULT_MODEL=${DEFAULT_MODEL:-gpt-3.5-turbo}
      - BASE_URL=${BASE_URL:-https://openrouter.ai/api/v1}
    volumes:
      # Mount source code for development
      - ./src:/app/src
      - ./config:/app/config
      - ./patterns:/app/patterns
      # NOTE: To use your local ~/.askai/config.yml file, create a docker-compose.override.yml with:
      # services:
      #   askai-api:
      #     volumes:
      #       - ${HOME}/.askai/config.yml:/tmp/host-config.yml:ro
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/v1/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Optional: Add a reverse proxy for production
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./docker/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - askai-api
    profiles:
      - production
    restart: unless-stopped

networks:
  default:
    name: askai-network